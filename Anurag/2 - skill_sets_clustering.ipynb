{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characteristics and skill sets required as put in the job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19001, 24)\n",
      "(16689, 24)\n",
      "Removed 2312 duplicates (based on RequiredQual)\n"
     ]
    }
   ],
   "source": [
    "df_ori = pd.read_csv('../data/data job posts.csv')\n",
    "df_ori.head()\n",
    "print(df_ori.shape)\n",
    "df = df_ori.drop_duplicates(['RequiredQual'])\n",
    "print(df.shape)\n",
    "print(\"Removed {0} duplicates (based on RequiredQual)\".format(df_ori.shape[0]-df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    To perform this job successfully, an\\r\\nindivi...\n",
       "1    - Bachelor's Degree; Master's is preferred;\\r\\...\n",
       "2    - Degree in environmentally related field, or ...\n",
       "3    - Advanced degree in public health, social sci...\n",
       "4    - University degree; economical background is ...\n",
       "Name: RequiredQual, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"RequiredQual\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[\"RequiredQual\"] = df[\"RequiredQual\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['RequiredQual_token'] = df['RequiredQual'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the tokens using the following steps:\n",
    "### a. Remove punctuation\n",
    "### b. Change to lower case\n",
    "### c. remove stop words\n",
    "### d. Lemmatize nouns only refer [here](https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word)\n",
    "### e. Keep only the tokens that are of length 3 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokens):\n",
    "    tokens_nop = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens_nop = [t.lower() for t in tokens_nop]\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    stop = stopwords.words('english')\n",
    "    tokens_nostop = [t for t in tokens_nop if t not in stop]\n",
    "    tokens_lem = [wnl.lemmatize(t) for t in tokens_nostop]\n",
    "    tokens_clean = [t for t in tokens_lem if len(t) >= 3]\n",
    "    return tokens_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['RequiredQual_processed'] = df.RequiredQual_token.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [perform, job, successfully, individual, must,...\n",
       "1    [bachelor, degree, master, preferred, excellen...\n",
       "2    [degree, environmentally, related, field, year...\n",
       "3    [advanced, degree, public, health, social, sci...\n",
       "4    [university, degree, economical, background, p...\n",
       "Name: RequiredQual_processed, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RequiredQual_processed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the co-occurance vectors for the terms following the steps [here](https://stackoverflow.com/questions/17458751/python-symmetric-word-matrix-using-nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "# set the default value when a key is not present in the default dict\n",
    "# sparse matrix is a dict of dicts, the value is the co-occurance value\n",
    "sparse_matrix = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for job_qualification_tokens in df['RequiredQual_processed']:\n",
    "    for word1 in job_qualification_tokens:\n",
    "        for word2 in job_qualification_tokens:\n",
    "            sparse_matrix[word1][word2]+=1\n",
    "            \n",
    "print(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
